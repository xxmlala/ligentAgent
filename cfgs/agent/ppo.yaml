_target_: agent.ppo.PPOAgent
nstep: ${nstep}
# action_dims: [3, 4, 13, 13, 2, 2, 2]
action_dims: [7] # 
# action_dims: [4] #(no op, forward, turn left/right)
# action_dims: [3] #(forward, turn left/right)
# action_dims: [3,2,3]
hidden_dim: 400 #[300, 400]
hidden_depth: 3
gamma: 0.99
tau: 0.005
lr: 3.0e-4
clip_range: 0.2
value_clip_range: null
value_coef: 1
entropy_coef: 0.01
update_epochs: 10
mini_batch_size: ${train.batch_size}

actor:
  hidden_dim: 256
  hidden_depth: 3

critic:
  hidden_dim: 256
  hidden_depth: 3